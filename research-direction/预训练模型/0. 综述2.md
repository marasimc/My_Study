# 预训练语言模型（PLMs）

> 内容来自：
>
>  https://d223302.github.io/AACL2022-Pretrain-Language-Model-Tutorial/
>
> https://d223302.github.io/AACL2022-Pretrain-Language-Model-Tutorial/lecture_material/AACL_2022_tutorial_PLMs.pdf

预训练语言模型(PLMs)是在大规模语料库上以自监督方式进行预训练的语言模型。在过去的几年中，这些PLM从根本上改变了自然语言处理社区。传统的自监督预训练任务主要涉及**恢复损坏的输入句子，或自回归语言建模**。在对这些PLM进行预训练后，可以对下游任务进行微调。按照惯例，这些微调包括`在PLM之上添加一个线性层，并在下游任务上训练整个模型；或将下游任务表述为句子补全任务，并以seq2seq的方式微调下游任务`。在下游任务上对PLM进行微调通常会带来非凡的性能提升，这就是plm如此受欢迎的原因。

**在本教程中，从两个角度提供广泛而全面的介绍:为什么这些PLM有效，以及如何在NLP任务中使用它们。**

> - 第一部分对PLM进行了一些有见地的分析，部分解释了PLM出色的下游性能。其中一些结果帮助研究人员设计更好的预训练和微调方法
> - 第二部分首先关注如何将对比学习应用于PLM，以改进由PLM提取的表示，然后说明如何在不同情况下将这些PLM应用于下游任务。这些情况包括在数据稀缺的情况下对PLM进行微调，以及使用具有参数效率的PLM。

## Part 1 Introduction



## Part 2 Why do PLMs work