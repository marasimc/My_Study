# 深度生成模型

> reference:
>
> https://zhuanlan.zhihu.com/p/50278440
>
> https://zhuanlan.zhihu.com/p/543565311

根据深度申城模型处理似然函数的不同方法将模型分为三类：

- **近似方法**：包括采用抽样方法近似计算似然函数的受限玻尔兹曼机(Restricted Boltzmann machine, RBM)和以受限玻尔兹曼机为基础模块的深度置信网络(Deep belief network, DBN)、深度玻尔兹曼机(Deep Boltzmann machines, DBM)和亥姆霍兹机, 与之对应的另一种模型是直接优化似然函数变分下界的变分自编码器以及其重要的改进模型, 包括重要性加权自编码和可用于半监督学习的深度辅助深度模型；
- **避开求极大似然过程的隐式方法**：代表模型是通过生成器和判别器之间的对抗行为来优化模型参数从而巧妙避开求解似然函数的生成对抗网络以及重要的改进模型, 包括WGAN、深度卷积生成对抗网络和当前最顶级的深度生成模型BigGAN；
- **对似然函数进行适当变形的流模型和自回归模型**：流模型利用可逆函数构造似然函数后直接优化模型参数, 包括以NICE为基础的常规流模型、变分流模型和可逆残差网络(i-ResNet), 自回归模型(NADE)将目标函数分解为条件概率乘积的形式, 包括神经自回归密度估计(NADE)、像素循环神经网络(PixelRNN)、掩码自编码器(MADE)以及WaveNet等.



深度生成模型基本都是以某种方式寻找并表达（多变量）数据的概率分布，分类有：

- 基于无向图模型（马尔可夫模型）的联合概率分布模型：构建隐含层(latent)和显示层（visible)的联合概率，然后去采样。
- 基于有向图模型（贝叶斯模型）的条件概率分布：寻找latent和visible之间的条件概率分布，也就是给定一个随机采样的隐含层，模型可以生成数据。

生成模型的训练是一个非监督过程，输入只需要无标签的数据；除了可以生成数据，还可以用于半监督的学习。比如，先利用大量无标签数据训练好模型，然后利用模型去提取数据特征（即从数据层到隐含层的编码过程），之后用数据特征结合标签去训练最终的网络模型。另一种方法是利用生成模型网络中的参数去初始化监督训练中的网络模型，当然，两个模型需要结构一致。