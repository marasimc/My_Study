# 概述

自然语言处理（NLP）
①从研究内容上：自然语言处理包括语法分析。语义分析、篇章理解
  从应用角度上：机器翻译、手写体和印刷体字符识别、语音识别及文语转换、信息检索、信息抽取与过滤、文本分类与聚类、舆情分析和观点挖掘等，它涉及与语言处理相关的数据挖掘、机器学习、知识获取、知识工程、人工智能研究和与语言计算相关的语言学研究等。
②面临的主要问题：如何考虑上下文影响（如指代词的纸袋对象）
                                各级语言单位的歧义问题，背景知识问题
③主要通过两种思路来进行自然语言处理，一种是基于规则的理性主义（人类语言主要是由语言规则来产生和描述的，只要能够用适当的形式将人类语言规则表示出来，就能够理解人类语言），
                                                                 另外一种是基于统计的经验主义（从语言数据中获取语言统计知识，有效建立语言的统计模型。因此只要能够有足够多的用于统计的语言数据，就能够理解人类语言）
   人类语言虽然有一定的规则，但是在真实使用中往往伴随大量的噪音和不规范性。
   对于经验主义方法而言，又不能无限地获取语言数据进行统计学习，因此也不能够完美地理解人类语言
自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。
④随着2013年word2vec技术的发表，以神经网络为基础的深度学习技术开始在自然语言处理中广泛使用，深度学习的分布式语义表示和多层网络架构具有强大的拟合和学习能力，显著提升了自然语言处理各种任务的性能，成为现阶段自然语言处理的主要技术方案。
⑤目前网络搜索引擎基本上还停留在关键词匹配，缺乏深层次的自然语言处理和理解。语音识别、文字识别、问答系统、机器翻译等目前也只能达到很基本的水平
⑥NLP/IR在单词层面的处理要比CV中的图像识别简单得多，只需要做一下tokenization、lemmatization、stemming等（中文复杂一些需要额外做自动分词），就可以利用关键词匹配完成很多任务，例如信息检索、文本分类、拼写纠错、情感分析、关键词提取等等，实际上已经得到非常广泛的应用，如搜索引擎、拼音输入法、新闻分类、阅读推荐等。

而由于图像中对象的复杂性和多样性，仅在对象识别层面，甚至特定的人脸识别，还有很多技术挑战。只不过是近年来，由于深度学习对非结构数据的强大表示和学习能力，开始让对象识别走向了实用化。

而进入到更高层面，例如面向图像的场景图构建，面向文本的句法语义分析，都需要对复杂语境（上下文）的精准而强大的建模能力。所以我感觉，并非NLP发展缓慢，只是两个领域的发展节奏和阶段不同。进入高层任务后，两个领域都将面临共同的关键挑战，都可以归结为复杂语境下的多对象（图像中是不同对象，文本中是不同概念）的语义组合问题。








第1周：文字嵌入讲座：介绍文字嵌入、分布式语义、LSA、Word2Vec、GloVe的用法和使用场景。讨论：单词和句子嵌入。
第2周：文本分类讲座：文本分类。文本表示的经典方法：BOW，TF-IDF。神经方法：嵌入，卷积，RNN。讨论课：卷积神经网络的薪酬预测; 解释网络预测。
第3周：语言模型讲座：语言模型，N-gram和神经方法; 可视化训练的模型。讨论课：使用语言模型生成ArXiv论文。
第4周：Seq2seq/注意力机制讲座：Seq2seq：编码器 - 解码器框架。Attention：Bahdanau模型。讨论课：酒店和宿舍描述的机器翻译。
第5周：结构化学习讲座：结构化学习 (Structured Learning) ，结构化感知器，结构化预测，RL基础知识。讨论课：POS标签。第6周：最大期望算法 (EM)讲座：期望最大化和单词对齐模型。讨论课：实现期望最大化。
第7周：机器翻译讲座：机器翻译，回顾PBMT的主要思想，过去3年NMT开发的应用程序特定思想以及该领域的一些开放性问题。讨论课：学生演讲。
第8周：迁移学习与多任务学习讲座：网络学习的内容和原因：“模型”永远不仅仅是“模型”！NLP中的多任务学习，如何理解，模型表示包含哪些信息。讨论课：通过与其他任务共同学习，提高指定实体的认可度
第9周：域适应 (Domain Adaptation)讲座：一般理论。示例加权 (Instance Weighting) 。代理标签(Proxy-Labels) 方法。特征匹配 (Feature Matching) 方法。类蒸馏 (Distillation-Like) 方法。讨论：让通用的机翻模型去适应特定的领域。
第10周：对话系统任务导向的对话系统 vs 一般对话系统 (Task-Oriented vs General) 。任务导向系统的框架概述。一般对话：检索与生成是两种方法。针对一般对话的生成模型；针对一般对话的基于检索的模型。讨论课：基于检索的简单问答。
第11周：对抗学习与潜变量讲座：先复习生成模型。后面讲生成对抗模型 (GAN) ，以及变分自编码器 (VAE)  ，以及这些东西为何重要。