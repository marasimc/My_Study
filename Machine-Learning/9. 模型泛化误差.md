# 模型的泛化误差（generalization error）

**reference：  [如 何 涨 点： 机器学习泛化误差全解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/521667255)        [模型泛化误差 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/446298196)**

  

​	在机器学习中，用训练数据集去训练（学习）一个model（模型），通常的做法是定义一个Loss function（误差函数），通过将Loss（或者叫error）最小化，来提高模型的性能（performance）。

​	然而学习一个模型的目的是为了解决实际的问题（或者说是训练数据集这个领域（field）中的一般化问题），单纯地将训练数据集的loss最小化，并不能保证在解决更一般的问题时模型仍然是最优，甚至不能保证模型是可用的。这个训练数据集的loss与一般化的数据集的loss之间的差异就叫泛化误差。

## 1. 泛化误差的分解

​	泛化误差可度量模型泛化能力。**“偏差-方差分解”**是解释学习算法泛化性能的一种重要工具。它试图对模型的期望泛化错误率进行拆解。泛化误差可分解为偏差(Bias)，方差(Variance) 和噪声(Noise)之和。其中可控的是模型偏差(Bias)和模型方差(Variance)，而Bias和Variance分别从两个方面来描述了学习到的模型与真实模型之间的差距。generalization error又可以细分为Bias和Variance两个部分。偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给定学习任务，为取得好的泛化能力，则需使偏差Bias较小，即能够充分拟合数据；并且使方差Bias较小，即使得数据扰动产生的影响小。

泛化误差虽然无法被直接计算，但是可以被分解为三部分：

> 1. 偏差bias：指排除噪声的影响后，预测值和目标值的平均偏移程度。偏差更多的是针对某个模型输出的样本误差，偏差是模型无法准确表达数据关系导致，比如模型过于简单，非线性的数据关系采用线性模型建模，偏差较大的模型是错的模型。Bias是 “用所有可能的训练数据集训练出的所有模型的输出的平均值” 与 “真实模型”的输出值之间的差异，度量了学习模型的**期望预测与真实结果的偏离程度，**即刻画了模型**本身的拟合能力。**
> 2. 方差 variance：模型方差不是针对某一个模型输出样本进行判定，而是指多个(次)模型输出的结果之间的离散差异，注意是多个模型或者多次模型，即**不同模型或同一模型不同时间的输出结果方差较大**。比如两条几乎相同的样本，但是预测值可能差很多。方差是由训练集的数据不够导致的，一方面量 (数据量) 不够，有限的数据集过度训练导致模型复杂，另一方面质(样本质量)不行，测试集中的数据分布未在训练集中，导致每次抽样训练模型时，每次模型参数不同，输出的结果都无法准确的预测出正确结果。 Variance是“不同的训练数据集训练出的模型”的输出值之间的差异，度量了同样大小的**训练集的变动所导致的学习性能变化，**即刻画了**数据扰动所造成的影响。**
> 3. 贝叶斯误差 bayes error / 残差/ 噪声：模型残差是指预测值与真实值之间的差异。残差和模型偏差的定义很接近，两者的区别是模型偏差是由模型拟合度不够导致的，而残差是模型准确但仍然与实值有一定的差异，可理解成噪声。噪声是随机的，意味着不可预测，而模型偏差不是随机产生的，可通过一定的特征工程进行预测。**噪声**表达了**在当前任务上任何学习算法所能达到的期望泛化误差的下界，**即刻画了**学习问题本身的难度。**

<img src="https://pic2.zhimg.com/80/v2-4e80432c8c5f01b6241bc8f3ca1e369d_720w.webp" alt="img" style="zoom:67%;" />

<img src="https://pic1.zhimg.com/80/v2-3b9ae89db0fab92b7377882c69aceea0_720w.webp" alt="img" style="zoom:80%;" />

​	有许多关于欠拟合和过拟合的文章都是从模型的角度出发讲如何减小偏差和方差，最后一个噪声，或者说贝叶斯误差，经常会被忽略掉，因为模型上没有什么可操作的空间。但是现实中数据集也是可以操作的， 而且即使是在比赛和学术数据集上大家进行的**数据清洗和预处理的工作，**也可以认为是在一定程度上**控制贝叶斯误差，降低学习难度**。

## 2. 影响误差的因素

![img](https://pic3.zhimg.com/80/v2-f3a9f14eb55904e12e362acaa088d902_720w.webp)

### 2.1 先验假设

​	先验假设来自于目标数据集所在领域的专业知识，它和其他因素，以及机器学习的各个步骤都息息相关。著名的没有NFL（没有免费的午餐）理论就是在说，模型的好与坏是没有办法事先判断的，**除非能依赖可以成立的假设**。一个最简单的线性模型可能击败当前最高级的动辄几亿参数的神经网络，如果是在一个本来就是线性结构的数据集上。

而且如果先验知识拉满，我们对预测目标的概率分布了如指掌，接下来也不用机器学习了，剩下的工作应该叫公式推导。当先验知识不足，依赖了不成立的假设，比如用线性模型去拟合一个非线性的关系，就是对数据结构的错误判断而选择了不合适的模型。

### 2.2 数据的数量

一般情况下数据数量越多越好，数据结构越复杂也就需要更多的数据才能把这个结构给勾勒出来；模型越复杂通常也需要更多的数据来规避过拟合的风险。

非一般的情况需要特殊考虑。

### 2.3 具有代表性的数据

数据的数量再多，如果都坨在特征空间的一小块儿地方，那大部分都是**无效的数据**。机器学习中的**类别不平衡问题**其实就是数据不够具有代表性。

如何解决？

> 1. 尽可能避免[抽样偏差/选择性偏差](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Sampling_bias%23Distinction_from_selection_bias)，尤其是在一些影响大的特征方面。
>
> 2. 做调查时需要注意的幸存者偏差([Survivorship bias](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Survivorship_bias))，确认偏差([confirmation bias](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Confirmation_bias))都是**选择性偏差导致**无法保证**随机性**。如果调查对象集中一个特定群体比如女性，那么性别这个特征对结果的影响就没有办法被模型学习到了。

不平衡的，多出来的数据就完全没有用吗？也不一定，可以用bagging的方式在子学习器上投入平衡后的数据集再集成起来试试。

### 2.4 数据的质量

可以利用常识/专业知识来一定程度上控制噪声；对于某些连续数值特征，如果我们事先知道收集这些数据时测量误差比较大的话，也可以事先对这些数据分桶。

### 2.5 数据的维度/特征

有意义的特征！

### 2.6 模型的选择和调参

根据训练和测试误差来调整模型的复杂度、训练时间和正则化措施。

模型的调参可以使用自动调参工具：[Optuna - A hyperparameter optimization framework](https://optuna.org/)

## 3. 总结

### 3.1 贝叶斯误差（噪声）

​	**噪声的存在是因为数据集本身的结构就不明朗**，有时候特征一模一样的两个样本，目标值也可能不同，比如对一张同时存在猫和狗的照片进行分类。这可能是数据集质量不佳、信息（特征维度）不足导致的。可以利用先验知识一定程度上改善误差带来的影响，尽可能收集重要的信息。

### 3.2 偏差

偏差的产生说明模型没有很好的学习到数据的结构。

模型方面：

> - 增加模型的复杂度
> - 增加训练时长
> - 减少正则化措施
> - 针对模型进行特征工程，比如线性模型学习不到非线性关系，如果能对数据进行处理使得其和目标的关系变成线性，那情况就好得多。其实和增加模型复杂度算是异曲同工了。

数据方面：

> - 保证数据集采样的随机性，多样性（覆盖应用时的各种场景）
> - **足够**的，**有效**的，**准确**的数据和特征

### 3.3 方差

方差的产生说明模型在训练集上**拟合到了不该学的噪声**。

> - 模型方面可以和欠拟合反着来，
> - 数据方面类似的，也是需要提高数据集的质量，去除无用的特征。
> - 数据增强和集成学习常常能有效的改善过拟合。



假如模型训练不足时，此时学习器的拟合能力不够强，数据的扰动不会对结果产生很大的影响（可以想象成由于训练的程度不够，此时学习器指学习到了一些所有的数据都有的一些特征），模型偏差主导了算法的泛化能力。

随着训练的进行，学习器的拟合能力逐渐增强，模型偏差逐渐减小，但此时不同通过数据学习得到的学习器就可能会有较大的偏差，即模型方差会主导模型的泛化能力。若学习进一步进行，学习器就可能学到数据集所独有的特征，而这些特征对于其它的数据是不适用的，训练数据发生的轻微扰动都会导致学习器发生显著变化，此时就发生了过拟合的现象。

模型过于简单必然导致偏差过大，过于复杂必然导致方差过大。以中间的虚线隔开，左边部分为欠拟合状态，右边部分为过拟合状态。一般情况下，模型偏差越小，方差越大，即模型训练的越复杂，训练集上的准确率越高，越可能过拟合。过拟合的表现就是模型的方差较大。

<img src="https://pic3.zhimg.com/80/v2-44de3323fc31e9f8638a3ced5796c85e_720w.webp" alt="img" style="zoom:80%;" />