# Attention介绍

***reference： https://zhuanlan.zhihu.com/p/342235515***



## 1. 背景知识

​	在Seq2Seq模型中，一般使用两个RNN，一个作为编码器，一个作为解码器：**编码器的作用是将输入数据编码成一个特征向量，然后解码器将这个特征向量解码成预测结果**，如图1所示：

<img src="assets\5. Attention\image-20221112153014285.png" alt="image-20221112153014285" style="zoom:70%;" />

​	这个模型的问题是只将编码器的最后一个节点的结果进行了输出，但是对于一个序列长度特别长的特征来说，这种方式无疑将会遗忘大量的前面时间片的特征，如图2所示。

![image-20221112153125278](assets\5. Attention\image-20221112153125278.png)

为什么不给解码器提供更好的特征呢？与其输入最后一个时间片的结果，不如将每个时间片的输出都提供给解码器 ——解码器如何使用这些特征——在编码器和解码器中间添加一个Attention

<img src="assets\5. Attention\image-20221112153315059.png" alt="image-20221112153315059" style="zoom:60%;" />

​	在这里，**Attention是一个介于编码器和解码器之间的一个接口，用于将编码器的编码结果以一种更有效的方式传递给解码器**。一个特别简单且有效的方式就是让解码器知道哪些特征重要，哪些特征不重要，即让解码器明白如何进行当前时间片的预测结果和输入编码的对齐，如图4所示。**Attention模型学习了编码器和解码器的对齐方式**，因此也被叫做**对齐模型（Alignment Model）**。

<img src="assets\5. Attention\image-20221112153637677.png" alt="image-20221112153637677" style="zoom:67%;" />

​	Attention有两种类型，一种是作用到编码器的全部时间片，这种Attention叫做全局（Global）Attention；另外一种只作用到时间片的一个子集，叫做局部（Local）Attention

## 2. Attention介绍

根据上面介绍，Attention可以分为4步：

**Step 1: 生成编码节点**

​	将输入数据依次输入到RNN中，得到编码器每个时间片的隐层状态的编码结果（绿色），并将编码器的最后一个输出作为解码器的第一个输入隐层状态（红色，decoder hidden state）。在下图的例子中，有4个隐层节点的状态和1个解码器的输入状态。

<img src="https://pic2.zhimg.com/v2-bbf6fa286f550da7397b2760150b5c29_b.webp" alt="动图" style="zoom:50%;" />

**step 2: 为每个编码器的隐层状态计算一个得分**

​	使用当前编码器的当前时间片的隐层状态和解码器的隐层状态计算一个得分，得分的计算方式有多种，这里使用的是点乘操作。

```
decoder_hidden = [10, 5, 10]

encoder_hidden  score
---------------------
     [0, 1, 1]     15 (= 10×0 + 5×1 + 10×1, the dot product)
     [5, 0, 1]     60
     [1, 1, 0]     15
     [0, 5, 1]     35
```

<img src="https://pic3.zhimg.com/v2-515a01ef88bd72bcacfd322f8a050f42_b.webp" alt="动图" style="zoom:50%;" />

**step 3: 使用softmax对得分进行归一化**

​	将softmax作用到step 2得到的score之上，得到和为1的分数。在实际场景中这个值往往是介于0和1之间的一个浮点数。

```
encoder_hidden  score  score^
-----------------------------
     [0, 1, 1]     15       0
     [5, 0, 1]     60       1
     [1, 1, 0]     15       0
     [0, 5, 1]     35       0
```

![动图](https://pic2.zhimg.com/v2-db0642e2aa949ba0cbc7c1b93ef773bd_b.webp)

**step 4: 使用score对隐层状态进行加权**

​	将score以及隐层状态进行点乘操作，得到加权之后的特征，这个特征也叫做对齐特征（Alignment Vector）或者注意力特征（Attention Vector）。

```
encoder  score  score^  alignment
---------------------------------
[0, 1, 1]   15      0   [0, 0, 0]
[5, 0, 1]   60      1   [5, 0, 1]
[1, 1, 0]   15      0   [0, 0, 0]
[0, 5, 1]   35      0   [0, 0, 0]
```

![动图](https://pic4.zhimg.com/v2-bbf7f1a57b1d0d89e949ec7405249663_b.webp)

**step 5: 加和特征向量**

​	这一步是将加权之后的特征进行加和，得到最终的编码器的特征向量。

```
encoder  score  score^  alignment
---------------------------------
[0, 1, 1]   15     0  [0, 0, 0]
[5, 0, 1]   60     1  [5, 0, 1]
[1, 1, 0]   15     0  [0, 0, 0]
[0, 5, 1]   35     0  [0, 0, 0]
context = [0+5+0+0, 0+0+0+0, 0+1+0+0] = [5, 0, 1]
```

![动图](https://pic1.zhimg.com/v2-c225993243ed84d38149cd4c7397b074_b.webp)

**step 6: 将特征向量应用的解码器**

最后一步是将含有Attention的编码器编码的结果提供给解码器进行解码，**注意每个时间片的Attention的结果会随着decoder hidden state的改变而更改**。

![动图](https://pic4.zhimg.com/v2-a443ae39e04005901dafd1ae8bbbb97b_b.webp)



## 3. 经典Attention模型

### 3.1 Bahdanau et. al (2015) 

1. 编码器是双向GRU，解码器是单向GRU，解码器的初始化输入是反向GRU的输出；
2. Attention操作选择的是additive/concat；
3. 解码器的输入特征是上一个时间片的预测结果和解码器的编码结果拼接而成的;
4. BLEU值为26.75

<img src="https://pic2.zhimg.com/80/v2-fa5fb3c1340d70d858f64b94947cdaf1_720w.webp" alt="img" style="zoom:80%;" />

### 3.2 Luong et. al (2015)

1. 编码器和解码器都是两层的LSTM；
2. 解码器的初始化隐层状态分别是两个解码器的最后一个时间片的输出；
3. 在论文中他们尝试了(i) additive/concat, (ii) dot product, (iii) location-based, 以及(iv) 'general'；
4. 将解码器得到的结果和编码器进行拼接，送入一个FFNN中得到最终的结果；
5. BLEU值为25.9。

<img src="https://pic1.zhimg.com/80/v2-234d5a57cd0b1c8088eec057e8fc1634_720w.webp" alt="img" style="zoom:80%;" />

### 3.3 Google’s Neural Machine Translation (GNMT)

1. 编码器是一个8层的LSTM。第一个层是双向的LSTM，把它们的特征拼接够提供给第二层，在后面的每一层LSTM都使用残差进行连接；
2. 解码器是使用的8层单向LSTM并使用残差结构进行连接；
3. score function和3.1相同，为addition/concat；
4. 拼接方式也和3.1相同；
5. 英法翻译的BLEU为38.95，英德翻译的BLEU为24.17。

<img src="https://pic1.zhimg.com/80/v2-5d39f0acb0f162ab5504e43b9c62e728_720w.webp" alt="img" style="zoom:67%;" />

## 4. 总结

​	Attention是当前深度学习中非常好用的一个模块，attention虽然简单，但其中也蕴含了一些怎么使用的技巧。另外介绍的三个NMT模型也是非常经典的机器翻译框架，其中网络结构的构建也给后面类似的模型提供了很好的参考。